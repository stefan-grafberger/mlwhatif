{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "fake = Faker()\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "fake.seed = seed\n",
    "random.seed = seed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def generate_data(num_records):\n",
    "\n",
    "    patient_data = []\n",
    "    history_data = []\n",
    "\n",
    "    for _ in range(0, num_records):\n",
    "        smokes = np.random.rand() > 0.75\n",
    "\n",
    "        is_male = np.random.rand() > 0.5\n",
    "        gave_consent = np.random.rand() > 0.02\n",
    "        if is_male:\n",
    "            weight = np.random.normal(loc=80, scale=5.0)\n",
    "        else:\n",
    "            weight = np.random.normal(loc=60, scale=3.0)\n",
    "\n",
    "        complication_prob = 0.15\n",
    "\n",
    "        if smokes:\n",
    "           complication_prob += 0.60\n",
    "\n",
    "        if is_male and weight > 90:\n",
    "           complication_prob += 0.70\n",
    "        elif is_male and weight > 85:\n",
    "           complication_prob += 0.20\n",
    "\n",
    "        if weight < 45:\n",
    "           complication_prob += 0.50\n",
    "\n",
    "        if complication_prob > 0.30 and np.random.rand() > 0.5:\n",
    "            notes = \"high risk\"\n",
    "        else:\n",
    "            notes = \"normal risk\"\n",
    "\n",
    "        has_complication = np.random.rand() < complication_prob\n",
    "\n",
    "        smokes_cat = 'no'\n",
    "        if smokes:\n",
    "            smokes_cat = 'yes'\n",
    "\n",
    "        hospital = random.choice([\"AL\", \"AK\", \"AR\", \"AZ\"])\n",
    "\n",
    "        ssn = fake.ssn()\n",
    "\n",
    "        patient_data.append((smokes_cat, weight, gave_consent, ssn))\n",
    "        history_data.append((notes, has_complication, ssn, hospital))\n",
    "\n",
    "    patients = pd.DataFrame.from_records(patient_data, columns=['smokes', 'weight', 'gave_consent', 'ssn'])\n",
    "    histories = pd.DataFrame.from_records(history_data, columns=['notes', 'has_complication', 'ssn', 'hospital'])\n",
    "    return patients, histories"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "  smokes     weight  gave_consent          ssn        notes  has_complication  \\\n0     no  83.312545          True  429-75-2175  normal risk             False   \n1     no  83.376232          True  625-61-3089  normal risk             False   \n2     no  75.653765          True  025-67-8228  normal risk             False   \n3     no  64.274952          True  272-10-8089  normal risk             False   \n4     no  83.021544          True  041-10-9047  normal risk             False   \n5     no  79.084929          True  381-25-3122  normal risk             False   \n6    yes  61.324315          True  130-23-3826    high risk              True   \n7    yes  57.690382          True  516-80-6194  normal risk              True   \n8     no  77.041701          True  383-69-6773  normal risk             False   \n9     no  80.215780          True  893-85-0715  normal risk             False   \n\n  hospital  \n0       AZ  \n1       AZ  \n2       AR  \n3       AR  \n4       AK  \n5       AL  \n6       AK  \n7       AL  \n8       AZ  \n9       AZ  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>smokes</th>\n      <th>weight</th>\n      <th>gave_consent</th>\n      <th>ssn</th>\n      <th>notes</th>\n      <th>has_complication</th>\n      <th>hospital</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>no</td>\n      <td>83.312545</td>\n      <td>True</td>\n      <td>429-75-2175</td>\n      <td>normal risk</td>\n      <td>False</td>\n      <td>AZ</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>no</td>\n      <td>83.376232</td>\n      <td>True</td>\n      <td>625-61-3089</td>\n      <td>normal risk</td>\n      <td>False</td>\n      <td>AZ</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>no</td>\n      <td>75.653765</td>\n      <td>True</td>\n      <td>025-67-8228</td>\n      <td>normal risk</td>\n      <td>False</td>\n      <td>AR</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>no</td>\n      <td>64.274952</td>\n      <td>True</td>\n      <td>272-10-8089</td>\n      <td>normal risk</td>\n      <td>False</td>\n      <td>AR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>no</td>\n      <td>83.021544</td>\n      <td>True</td>\n      <td>041-10-9047</td>\n      <td>normal risk</td>\n      <td>False</td>\n      <td>AK</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>no</td>\n      <td>79.084929</td>\n      <td>True</td>\n      <td>381-25-3122</td>\n      <td>normal risk</td>\n      <td>False</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>yes</td>\n      <td>61.324315</td>\n      <td>True</td>\n      <td>130-23-3826</td>\n      <td>high risk</td>\n      <td>True</td>\n      <td>AK</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>yes</td>\n      <td>57.690382</td>\n      <td>True</td>\n      <td>516-80-6194</td>\n      <td>normal risk</td>\n      <td>True</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>no</td>\n      <td>77.041701</td>\n      <td>True</td>\n      <td>383-69-6773</td>\n      <td>normal risk</td>\n      <td>False</td>\n      <td>AZ</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>no</td>\n      <td>80.215780</td>\n      <td>True</td>\n      <td>893-85-0715</td>\n      <td>normal risk</td>\n      <td>False</td>\n      <td>AZ</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_patients, tmp_histories = generate_data(10)\n",
    "tmp_patients.merge(tmp_histories, on=\"ssn\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, label_binarize, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_patients, train_histories = generate_data(10000)\n",
    "test_patients, test_histories = generate_data(4000)\n",
    "merged_patients = pd.concat([train_patients, test_patients])\n",
    "\n",
    "train_data = merged_patients.merge(train_histories, on=\"ssn\")\n",
    "test_data = merged_patients.merge(test_histories, on=\"ssn\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 16:21:38.753319: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-14 16:21:38.794313: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 0s 446us/step - loss: 0.6494 - accuracy: 0.7032\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 0s 470us/step - loss: 0.5455 - accuracy: 0.7927\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 0s 431us/step - loss: 0.5120 - accuracy: 0.7991\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 0s 429us/step - loss: 0.4946 - accuracy: 0.8002\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 0s 427us/step - loss: 0.4894 - accuracy: 0.7993\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "125/125 [==============================] - 0s 360us/step - loss: 0.4756 - accuracy: 0.8155\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.815500020980835"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode = ColumnTransformer(transformers=[\n",
    "    ('numerical_features', StandardScaler(), ['weight']),\n",
    "    ('categorical_features', OneHotEncoder(handle_unknown='ignore'), ['smokes']),\n",
    "    ('textual_features', HashingVectorizer(ngram_range=(1, 2), n_features=10), 'notes')])\n",
    "\n",
    "def create_mlp():\n",
    "    nn = Sequential([\n",
    "        Dense(8, activation='relu'), Dropout(0.3),\n",
    "        Dense(4, activation='relu'),\n",
    "        Dense(2, activation='softmax')])\n",
    "    nn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics='accuracy')\n",
    "    return nn\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', encode),\n",
    "    ('learner', KerasClassifier(create_mlp, epochs=5))])\n",
    "\n",
    "model = pipeline.fit(train_data, train_data.has_complication)\n",
    "model.score(test_data, test_data.has_complication)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 372us/step - loss: 408.8421 - accuracy: 0.7072\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7072499990463257"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_test_patients, corrupted_test_histories = generate_data(4000)\n",
    "\n",
    "corrupted_test_patients.loc[corrupted_test_patients.sample(frac=0.2).index, 'weight'] = 0\n",
    "corrupted_test_patients.loc[corrupted_test_patients.sample(frac=0.2).index, 'weight'] = 60000\n",
    "\n",
    "corrupted_test_data = corrupted_test_patients.merge(corrupted_test_histories, on=\"ssn\")\n",
    "model.score(corrupted_test_data, corrupted_test_data.has_complication)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "merged_patients = pd.concat([train_patients, corrupted_test_patients])\n",
    "merged_patients.to_csv('patients.csv', index=False)\n",
    "train_histories.to_csv('histories.csv', index=False)\n",
    "corrupted_test_histories.to_csv('test_histories.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}