{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import statistics\n",
    "from typing import Dict, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_csv_results():\n",
    "    normal_datasets = [\"healthcare\", \"folktables\", \"cardio\", \"reviews\"]\n",
    "    image_dataset = [\"sneakers\"]\n",
    "    # data_loadings = [\"fast_loading\", \"slow_loading\"]\n",
    "    data_loadings = [\"fast_loading\"]\n",
    "    featurizations = [\"featurization_0\", \"featurization_1\", \"featurization_2\", \"featurization_3\", \"featurization_4\"]\n",
    "    models = [\"logistic_regression\", \"xgboost\", \"neural_network\"]\n",
    "    result_df = None\n",
    "    for dataset in normal_datasets:\n",
    "        for data_loading in data_loadings:\n",
    "            for featurization in featurizations:\n",
    "                for model in models:\n",
    "                    filepath = f\"{os.getcwd()}/instrumentation-benchmark-results/\" \\\n",
    "                               f\"results-instrumentation-{dataset}-{data_loading}-{featurization}-{model}.csv\"\n",
    "                    new_df = pd.read_csv(filepath)\n",
    "                    new_df['median_total_exec_duration_with_instrum_with_tracking'] = new_df['total_exec_duration_with_instrum_with_tracking'].median()\n",
    "                    new_df['median_total_exec_duration_with_instrum_without_tracking'] = new_df['total_exec_duration_with_instrum_without_tracking'].median()\n",
    "                    new_df['median_total_exec_duration_without_instrum_main_func'] = new_df['total_exec_duration_without_instrum_main_func'].median()\n",
    "                    new_df['median_total_exec_duration_without_instrum_load_ast_compile'] = new_df['total_exec_duration_without_instrum_load_ast_compile'].median()\n",
    "                    new_df['median_overhead_with_tracking_vs_main_func'] = new_df['median_total_exec_duration_with_instrum_with_tracking'] - new_df['median_total_exec_duration_without_instrum_main_func']\n",
    "                    new_df['instrum_with_tracking_original_pipeline_estimated'] = new_df['instrum_with_tracking_original_pipeline_estimated'].median()\n",
    "                    new_df['tracking_diff_of_measurement'] = new_df['instrum_with_tracking_original_pipeline_estimated'].median() - new_df['median_total_exec_duration_without_instrum_main_func']\n",
    "                    new_df = new_df[['median_total_exec_duration_with_instrum_with_tracking',\n",
    "                                     'median_total_exec_duration_with_instrum_without_tracking',\n",
    "                                     'median_total_exec_duration_without_instrum_main_func',\n",
    "                                     'median_total_exec_duration_without_instrum_load_ast_compile',\n",
    "                                     'median_overhead_with_tracking_vs_main_func',\n",
    "                                     'tracking_diff_of_measurement',\n",
    "                                     'instrum_with_tracking_original_pipeline_estimated',\n",
    "                                     'dataset', 'data_loading', 'featurization', 'model']]\n",
    "                    new_df = new_df.head(1)\n",
    "                    new_df = new_df.round(2)\n",
    "                    if result_df is None:\n",
    "                        result_df = new_df\n",
    "                    else:\n",
    "                        result_df = pd.concat([result_df, new_df], axis=0)\n",
    "    for dataset in image_dataset:\n",
    "        for data_loading in data_loadings:\n",
    "            for featurization in [\"image\"]:\n",
    "                for model in [\"image\"]:\n",
    "                    filepath = f\"{os.getcwd()}/instrumentation-benchmark-results/\" \\\n",
    "                               f\"results-instrumentation-{dataset}-{data_loading}-{featurization}-{model}.csv\"\n",
    "                    new_df = pd.read_csv(filepath)\n",
    "                    new_df['median_total_exec_duration_with_instrum_with_tracking'] = new_df['total_exec_duration_with_instrum_with_tracking'].median()\n",
    "                    new_df['median_total_exec_duration_with_instrum_without_tracking'] = new_df['total_exec_duration_with_instrum_without_tracking'].median()\n",
    "                    new_df['median_total_exec_duration_without_instrum_main_func'] = new_df['total_exec_duration_without_instrum_main_func'].median()\n",
    "                    new_df['median_total_exec_duration_without_instrum_load_ast_compile'] = new_df['total_exec_duration_without_instrum_load_ast_compile'].median()\n",
    "                    new_df['median_overhead_with_tracking_vs_main_func'] = new_df['median_total_exec_duration_with_instrum_with_tracking'] - new_df['median_total_exec_duration_without_instrum_main_func']\n",
    "                    new_df['instrum_with_tracking_original_pipeline_estimated'] = new_df['instrum_with_tracking_original_pipeline_estimated'].median()\n",
    "                    new_df['tracking_diff_of_measurement'] = new_df['instrum_with_tracking_original_pipeline_estimated'].median() - new_df['median_total_exec_duration_without_instrum_main_func']\n",
    "                    new_df = new_df[['median_total_exec_duration_with_instrum_with_tracking',\n",
    "                                     'median_total_exec_duration_with_instrum_without_tracking',\n",
    "                                     'median_total_exec_duration_without_instrum_main_func',\n",
    "                                     'median_total_exec_duration_without_instrum_load_ast_compile',\n",
    "                                     'median_overhead_with_tracking_vs_main_func',\n",
    "                                     'tracking_diff_of_measurement',\n",
    "                                     'instrum_with_tracking_original_pipeline_estimated',\n",
    "                                     'dataset', 'data_loading', 'featurization', 'model']]\n",
    "                    new_df = new_df.head(1)\n",
    "                    new_df = new_df.round(2)\n",
    "                    if result_df is None:\n",
    "                        result_df = new_df\n",
    "                    else:\n",
    "                        result_df = pd.concat([result_df, new_df], axis=0)\n",
    "    return result_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "median_results = load_csv_results()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "    median_total_exec_duration_with_instrum_with_tracking  \\\n0                                            12413.91       \n0                                             7312.90       \n0                                            37060.52       \n0                                             3485.51       \n0                                             2065.38       \n..                                                ...       \n0                                            15473.76       \n0                                             8474.31       \n0                                            18958.99       \n0                                             9789.36       \n0                                            36162.44       \n\n    median_total_exec_duration_with_instrum_without_tracking  \\\n0                                            13018.21          \n0                                             7516.40          \n0                                            36845.65          \n0                                             3849.75          \n0                                             2041.97          \n..                                                ...          \n0                                            15448.05          \n0                                             8331.31          \n0                                            18790.77          \n0                                             9931.43          \n0                                            36158.13          \n\n    median_total_exec_duration_without_instrum_main_func  \\\n0                                            12516.55      \n0                                             7353.89      \n0                                            37076.82      \n0                                             3462.63      \n0                                             2035.96      \n..                                                ...      \n0                                            15131.04      \n0                                             8031.67      \n0                                            18515.74      \n0                                             9308.52      \n0                                            35560.26      \n\n    median_total_exec_duration_without_instrum_load_ast_compile  \\\n0                                            12177.02             \n0                                             7217.83             \n0                                            36208.55             \n0                                             3474.75             \n0                                             1867.68             \n..                                                ...             \n0                                            14943.45             \n0                                             8120.61             \n0                                            18486.48             \n0                                             9311.27             \n0                                            35737.68             \n\n    median_overhead_with_tracking_vs_main_func  tracking_diff_of_measurement  \\\n0                                      -102.64                       -523.56   \n0                                       -40.99                       -192.38   \n0                                       -16.30                       -371.63   \n0                                        22.88                       -152.92   \n0                                        29.42                       -168.80   \n..                                         ...                           ...   \n0                                       342.72                       -102.43   \n0                                       442.64                        -96.09   \n0                                       443.25                        -67.92   \n0                                       480.84                         61.46   \n0                                       602.18                        180.39   \n\n    instrum_with_tracking_original_pipeline_estimated     dataset  \\\n0                                            11992.99     reviews   \n0                                             7161.51    sneakers   \n0                                            36705.18     reviews   \n0                                             3309.70  folktables   \n0                                             1867.16  healthcare   \n..                                                ...         ...   \n0                                            15028.61     reviews   \n0                                             7935.57     reviews   \n0                                            18447.81     reviews   \n0                                             9369.98     reviews   \n0                                            35740.65     reviews   \n\n    data_loading    featurization                model  \n0   fast_loading  featurization_2       neural_network  \n0   fast_loading            image                image  \n0   fast_loading  featurization_2              xgboost  \n0   fast_loading  featurization_1       neural_network  \n0   fast_loading  featurization_1       neural_network  \n..           ...              ...                  ...  \n0   fast_loading  featurization_3       neural_network  \n0   fast_loading  featurization_4  logistic_regression  \n0   fast_loading  featurization_4              xgboost  \n0   fast_loading  featurization_3  logistic_regression  \n0   fast_loading  featurization_3              xgboost  \n\n[61 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>median_total_exec_duration_with_instrum_with_tracking</th>\n      <th>median_total_exec_duration_with_instrum_without_tracking</th>\n      <th>median_total_exec_duration_without_instrum_main_func</th>\n      <th>median_total_exec_duration_without_instrum_load_ast_compile</th>\n      <th>median_overhead_with_tracking_vs_main_func</th>\n      <th>tracking_diff_of_measurement</th>\n      <th>instrum_with_tracking_original_pipeline_estimated</th>\n      <th>dataset</th>\n      <th>data_loading</th>\n      <th>featurization</th>\n      <th>model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12413.91</td>\n      <td>13018.21</td>\n      <td>12516.55</td>\n      <td>12177.02</td>\n      <td>-102.64</td>\n      <td>-523.56</td>\n      <td>11992.99</td>\n      <td>reviews</td>\n      <td>fast_loading</td>\n      <td>featurization_2</td>\n      <td>neural_network</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>7312.90</td>\n      <td>7516.40</td>\n      <td>7353.89</td>\n      <td>7217.83</td>\n      <td>-40.99</td>\n      <td>-192.38</td>\n      <td>7161.51</td>\n      <td>sneakers</td>\n      <td>fast_loading</td>\n      <td>image</td>\n      <td>image</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>37060.52</td>\n      <td>36845.65</td>\n      <td>37076.82</td>\n      <td>36208.55</td>\n      <td>-16.30</td>\n      <td>-371.63</td>\n      <td>36705.18</td>\n      <td>reviews</td>\n      <td>fast_loading</td>\n      <td>featurization_2</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>3485.51</td>\n      <td>3849.75</td>\n      <td>3462.63</td>\n      <td>3474.75</td>\n      <td>22.88</td>\n      <td>-152.92</td>\n      <td>3309.70</td>\n      <td>folktables</td>\n      <td>fast_loading</td>\n      <td>featurization_1</td>\n      <td>neural_network</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2065.38</td>\n      <td>2041.97</td>\n      <td>2035.96</td>\n      <td>1867.68</td>\n      <td>29.42</td>\n      <td>-168.80</td>\n      <td>1867.16</td>\n      <td>healthcare</td>\n      <td>fast_loading</td>\n      <td>featurization_1</td>\n      <td>neural_network</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>15473.76</td>\n      <td>15448.05</td>\n      <td>15131.04</td>\n      <td>14943.45</td>\n      <td>342.72</td>\n      <td>-102.43</td>\n      <td>15028.61</td>\n      <td>reviews</td>\n      <td>fast_loading</td>\n      <td>featurization_3</td>\n      <td>neural_network</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>8474.31</td>\n      <td>8331.31</td>\n      <td>8031.67</td>\n      <td>8120.61</td>\n      <td>442.64</td>\n      <td>-96.09</td>\n      <td>7935.57</td>\n      <td>reviews</td>\n      <td>fast_loading</td>\n      <td>featurization_4</td>\n      <td>logistic_regression</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>18958.99</td>\n      <td>18790.77</td>\n      <td>18515.74</td>\n      <td>18486.48</td>\n      <td>443.25</td>\n      <td>-67.92</td>\n      <td>18447.81</td>\n      <td>reviews</td>\n      <td>fast_loading</td>\n      <td>featurization_4</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>9789.36</td>\n      <td>9931.43</td>\n      <td>9308.52</td>\n      <td>9311.27</td>\n      <td>480.84</td>\n      <td>61.46</td>\n      <td>9369.98</td>\n      <td>reviews</td>\n      <td>fast_loading</td>\n      <td>featurization_3</td>\n      <td>logistic_regression</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>36162.44</td>\n      <td>36158.13</td>\n      <td>35560.26</td>\n      <td>35737.68</td>\n      <td>602.18</td>\n      <td>180.39</td>\n      <td>35740.65</td>\n      <td>reviews</td>\n      <td>fast_loading</td>\n      <td>featurization_3</td>\n      <td>xgboost</td>\n    </tr>\n  </tbody>\n</table>\n<p>61 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_results_ordered_by_median_overhead = median_results\\\n",
    "    .sort_values(by=['median_overhead_with_tracking_vs_main_func'])\n",
    "median_results_ordered_by_median_overhead.to_csv(\n",
    "    f\"{os.getcwd()}/instrumentation-benchmark-results/instrumentation_overhead_overview_ordered_by_median_overhead.csv\",\n",
    "    index=True)\n",
    "median_results_ordered_by_median_overhead\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}