{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import statistics\n",
    "from typing import Dict, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_csv_results():\n",
    "    normal_datasets = [\"healthcare\", \"folktables\", \"cardio\", \"reviews\"]\n",
    "    image_dataset = [\"sneakers\"]\n",
    "    data_loadings = [\"fast_loading\", \"slow_loading\"]\n",
    "    featurizations = [\"featurization_0\", \"featurization_1\", \"featurization_2\", \"featurization_3\", \"featurization_4\"]\n",
    "    models = [\"logistic_regression\", \"xgboost\", \"neural_network\"]\n",
    "    result_df = None\n",
    "    for dataset in normal_datasets:\n",
    "        for data_loading in data_loadings:\n",
    "            for featurization in featurizations:\n",
    "                for model in models:\n",
    "                    filepath = f\"{os.getcwd()}/instrumentation-benchmark-results/\" \\\n",
    "                               f\"results-instrumentation-{dataset}-{data_loading}-{featurization}-{model}.csv\"\n",
    "                    new_df = pd.read_csv(filepath)\n",
    "                    new_df['median_total_exec_duration_with_instrum_with_tracking'] = new_df['total_exec_duration_with_instrum_with_tracking'].median()\n",
    "                    new_df['median_total_exec_duration_with_instrum_without_tracking'] = new_df['total_exec_duration_with_instrum_without_tracking'].median()\n",
    "                    new_df['median_total_exec_duration_without_instrum_main_func'] = new_df['total_exec_duration_without_instrum_main_func'].median()\n",
    "                    new_df['median_total_exec_duration_without_instrum_load_ast_compile'] = new_df['total_exec_duration_without_instrum_load_ast_compile'].median()\n",
    "                    new_df['median_overhead_with_tracking_vs_main_func'] = new_df['median_total_exec_duration_with_instrum_with_tracking'] - new_df['median_total_exec_duration_without_instrum_main_func']\n",
    "                    new_df['instrum_with_tracking_original_pipeline_estimated'] = new_df['instrum_with_tracking_original_pipeline_estimated'].median()\n",
    "                    new_df['tracking_diff_of_measurement'] = new_df['instrum_with_tracking_original_pipeline_estimated'].median() - new_df['median_total_exec_duration_without_instrum_main_func']\n",
    "                    new_df = new_df[['median_total_exec_duration_with_instrum_with_tracking',\n",
    "                                     'median_total_exec_duration_with_instrum_without_tracking',\n",
    "                                     'median_total_exec_duration_without_instrum_main_func',\n",
    "                                     'median_total_exec_duration_without_instrum_load_ast_compile',\n",
    "                                     'median_overhead_with_tracking_vs_main_func',\n",
    "                                     'tracking_diff_of_measurement',\n",
    "                                     'instrum_with_tracking_original_pipeline_estimated',\n",
    "                                     'dataset', 'data_loading', 'featurization', 'model']]\n",
    "                    new_df = new_df.head(1)\n",
    "                    new_df = new_df.round(2)\n",
    "                    if result_df is None:\n",
    "                        result_df = new_df\n",
    "                    else:\n",
    "                        result_df = pd.concat([result_df, new_df], axis=0)\n",
    "    for dataset in image_dataset:\n",
    "        for data_loading in data_loadings:\n",
    "            for featurization in [\"image\"]:\n",
    "                for model in [\"image\"]:\n",
    "                    filepath = f\"{os.getcwd()}/instrumentation-benchmark-results/\" \\\n",
    "                               f\"results-instrumentation-{dataset}-{data_loading}-{featurization}-{model}.csv\"\n",
    "                    new_df = pd.read_csv(filepath)\n",
    "                    new_df['median_total_exec_duration_with_instrum_with_tracking'] = new_df['total_exec_duration_with_instrum_with_tracking'].median()\n",
    "                    new_df['median_total_exec_duration_with_instrum_without_tracking'] = new_df['total_exec_duration_with_instrum_without_tracking'].median()\n",
    "                    new_df['median_total_exec_duration_without_instrum_main_func'] = new_df['total_exec_duration_without_instrum_main_func'].median()\n",
    "                    new_df['median_total_exec_duration_without_instrum_load_ast_compile'] = new_df['total_exec_duration_without_instrum_load_ast_compile'].median()\n",
    "                    new_df['median_overhead_with_tracking_vs_main_func'] = new_df['median_total_exec_duration_with_instrum_with_tracking'] - new_df['median_total_exec_duration_without_instrum_main_func']\n",
    "                    new_df['instrum_with_tracking_original_pipeline_estimated'] = new_df['instrum_with_tracking_original_pipeline_estimated'].median()\n",
    "                    new_df['tracking_diff_of_measurement'] = new_df['instrum_with_tracking_original_pipeline_estimated'].median() - new_df['median_total_exec_duration_without_instrum_main_func']\n",
    "                    new_df = new_df[['median_total_exec_duration_with_instrum_with_tracking',\n",
    "                                     'median_total_exec_duration_with_instrum_without_tracking',\n",
    "                                     'median_total_exec_duration_without_instrum_main_func',\n",
    "                                     'median_total_exec_duration_without_instrum_load_ast_compile',\n",
    "                                     'median_overhead_with_tracking_vs_main_func',\n",
    "                                     'tracking_diff_of_measurement',\n",
    "                                     'instrum_with_tracking_original_pipeline_estimated',\n",
    "                                     'dataset', 'data_loading', 'featurization', 'model']]\n",
    "                    new_df = new_df.head(1)\n",
    "                    new_df = new_df.round(2)\n",
    "                    if result_df is None:\n",
    "                        result_df = new_df\n",
    "                    else:\n",
    "                        result_df = pd.concat([result_df, new_df], axis=0)\n",
    "    return result_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "median_results = load_csv_results()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "    median_total_exec_duration_with_instrum_with_tracking  \\\n0                                            40247.47       \n0                                             1396.62       \n0                                             4100.87       \n0                                             4350.49       \n0                                             4296.83       \n..                                                ...       \n0                                            42873.42       \n0                                             9893.54       \n0                                            43339.14       \n0                                            15809.98       \n0                                            16321.41       \n\n    median_total_exec_duration_with_instrum_without_tracking  \\\n0                                            40258.47          \n0                                             1396.26          \n0                                             4102.06          \n0                                             4355.73          \n0                                             4317.16          \n..                                                ...          \n0                                            42862.47          \n0                                             9904.81          \n0                                            43334.18          \n0                                            15778.06          \n0                                            16301.24          \n\n    median_total_exec_duration_without_instrum_main_func  \\\n0                                            40450.81      \n0                                             1270.78      \n0                                             3967.05      \n0                                             4214.16      \n0                                             4157.94      \n..                                                ...      \n0                                            42314.11      \n0                                             9324.54      \n0                                            42769.35      \n0                                            15220.78      \n0                                            15706.52      \n\n    median_total_exec_duration_without_instrum_load_ast_compile  \\\n0                                            40019.55             \n0                                             1280.99             \n0                                             3960.17             \n0                                             4193.56             \n0                                             4155.53             \n..                                                ...             \n0                                            42339.82             \n0                                             9320.41             \n0                                            42784.73             \n0                                            15235.52             \n0                                            15717.91             \n\n    median_overhead_with_tracking_vs_main_func  tracking_diff_of_measurement  \\\n0                                      -203.34                       -520.75   \n0                                       125.84                        -24.39   \n0                                       133.82                         -9.90   \n0                                       136.34                        -37.14   \n0                                       138.90                         -6.04   \n..                                         ...                           ...   \n0                                       559.31                        195.54   \n0                                       568.99                        211.52   \n0                                       569.79                        203.04   \n0                                       589.20                        199.04   \n0                                       614.89                        211.08   \n\n    instrum_with_tracking_original_pipeline_estimated     dataset  \\\n0                                            39930.06     reviews   \n0                                             1246.39  folktables   \n0                                             3957.15    sneakers   \n0                                             4177.02  folktables   \n0                                             4151.90    sneakers   \n..                                                ...         ...   \n0                                            42509.65     reviews   \n0                                             9536.06     reviews   \n0                                            42972.38     reviews   \n0                                            15419.82     reviews   \n0                                            15917.61     reviews   \n\n    data_loading    featurization                model  \n0   slow_loading  featurization_2              xgboost  \n0   fast_loading  featurization_0  logistic_regression  \n0   fast_loading            image                image  \n0   fast_loading  featurization_2       neural_network  \n0   slow_loading            image                image  \n..           ...              ...                  ...  \n0   fast_loading  featurization_3              xgboost  \n0   slow_loading  featurization_3  logistic_regression  \n0   slow_loading  featurization_3              xgboost  \n0   fast_loading  featurization_3       neural_network  \n0   slow_loading  featurization_3       neural_network  \n\n[122 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>median_total_exec_duration_with_instrum_with_tracking</th>\n      <th>median_total_exec_duration_with_instrum_without_tracking</th>\n      <th>median_total_exec_duration_without_instrum_main_func</th>\n      <th>median_total_exec_duration_without_instrum_load_ast_compile</th>\n      <th>median_overhead_with_tracking_vs_main_func</th>\n      <th>tracking_diff_of_measurement</th>\n      <th>instrum_with_tracking_original_pipeline_estimated</th>\n      <th>dataset</th>\n      <th>data_loading</th>\n      <th>featurization</th>\n      <th>model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40247.47</td>\n      <td>40258.47</td>\n      <td>40450.81</td>\n      <td>40019.55</td>\n      <td>-203.34</td>\n      <td>-520.75</td>\n      <td>39930.06</td>\n      <td>reviews</td>\n      <td>slow_loading</td>\n      <td>featurization_2</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1396.62</td>\n      <td>1396.26</td>\n      <td>1270.78</td>\n      <td>1280.99</td>\n      <td>125.84</td>\n      <td>-24.39</td>\n      <td>1246.39</td>\n      <td>folktables</td>\n      <td>fast_loading</td>\n      <td>featurization_0</td>\n      <td>logistic_regression</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>4100.87</td>\n      <td>4102.06</td>\n      <td>3967.05</td>\n      <td>3960.17</td>\n      <td>133.82</td>\n      <td>-9.90</td>\n      <td>3957.15</td>\n      <td>sneakers</td>\n      <td>fast_loading</td>\n      <td>image</td>\n      <td>image</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>4350.49</td>\n      <td>4355.73</td>\n      <td>4214.16</td>\n      <td>4193.56</td>\n      <td>136.34</td>\n      <td>-37.14</td>\n      <td>4177.02</td>\n      <td>folktables</td>\n      <td>fast_loading</td>\n      <td>featurization_2</td>\n      <td>neural_network</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>4296.83</td>\n      <td>4317.16</td>\n      <td>4157.94</td>\n      <td>4155.53</td>\n      <td>138.90</td>\n      <td>-6.04</td>\n      <td>4151.90</td>\n      <td>sneakers</td>\n      <td>slow_loading</td>\n      <td>image</td>\n      <td>image</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>42873.42</td>\n      <td>42862.47</td>\n      <td>42314.11</td>\n      <td>42339.82</td>\n      <td>559.31</td>\n      <td>195.54</td>\n      <td>42509.65</td>\n      <td>reviews</td>\n      <td>fast_loading</td>\n      <td>featurization_3</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>9893.54</td>\n      <td>9904.81</td>\n      <td>9324.54</td>\n      <td>9320.41</td>\n      <td>568.99</td>\n      <td>211.52</td>\n      <td>9536.06</td>\n      <td>reviews</td>\n      <td>slow_loading</td>\n      <td>featurization_3</td>\n      <td>logistic_regression</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>43339.14</td>\n      <td>43334.18</td>\n      <td>42769.35</td>\n      <td>42784.73</td>\n      <td>569.79</td>\n      <td>203.04</td>\n      <td>42972.38</td>\n      <td>reviews</td>\n      <td>slow_loading</td>\n      <td>featurization_3</td>\n      <td>xgboost</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>15809.98</td>\n      <td>15778.06</td>\n      <td>15220.78</td>\n      <td>15235.52</td>\n      <td>589.20</td>\n      <td>199.04</td>\n      <td>15419.82</td>\n      <td>reviews</td>\n      <td>fast_loading</td>\n      <td>featurization_3</td>\n      <td>neural_network</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>16321.41</td>\n      <td>16301.24</td>\n      <td>15706.52</td>\n      <td>15717.91</td>\n      <td>614.89</td>\n      <td>211.08</td>\n      <td>15917.61</td>\n      <td>reviews</td>\n      <td>slow_loading</td>\n      <td>featurization_3</td>\n      <td>neural_network</td>\n    </tr>\n  </tbody>\n</table>\n<p>122 rows Ã— 11 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_results_ordered_by_median_overhead = median_results\\\n",
    "    .sort_values(by=['median_overhead_with_tracking_vs_main_func'])\n",
    "median_results_ordered_by_median_overhead.to_csv(\n",
    "    f\"{os.getcwd()}/instrumentation-benchmark-results/instrumentation_overhead_overview_ordered_by_median_overhead.csv\",\n",
    "    index=True)\n",
    "median_results_ordered_by_median_overhead\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}